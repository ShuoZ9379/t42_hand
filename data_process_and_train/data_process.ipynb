{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#never tear obj marker and paste again\n",
    "#try centralize the center of obj marker on obj\n",
    "#valid rmat and tvec should not change much during one idx of collection\n",
    "from process_params import *\n",
    "from sys import argv\n",
    "#argv idx1 idx2 idx3 idx4 idx5 ... nm ne suffxi(v1_,avi_,...)\n",
    "mix=False\n",
    "dm='nm'\n",
    "train_mode='ne'\n",
    "suffix='v1_'\n",
    "interval=10\n",
    "if len(argv)>1:\n",
    "    mix=True\n",
    "    if len(argv)<=3:\n",
    "        if argv[0][-10:]=='process.py':\n",
    "            mix_idx_ls=[int(argv[i+1]) for i in range(len(argv)-1)]\n",
    "        else:\n",
    "            mix=False\n",
    "    elif argv[-3][-1]!='m':\n",
    "        mix_idx_ls=[int(argv[i+1]) for i in range(len(argv)-1)]\n",
    "    else:\n",
    "        dm=argv[-3]\n",
    "        train_mode=argv[-2]\n",
    "        suffix=argv[-1]\n",
    "        mix_idx_ls=[int(argv[i+1]) for i in range(len(argv)-4)]\n",
    "        if mix_idx_ls==[]:\n",
    "            mix=False\n",
    "data_mode=data_mode[:-2]+dm\n",
    "import glob,pickle,os,copy\n",
    "import numpy as np\n",
    "\n",
    "def cali(memory,cali_path):\n",
    "    tmp=np.array(memory)\n",
    "    tmp=tmp[tmp[:,-1]==False]\n",
    "    tmp=np.array(list(tmp[:,2]))\n",
    "    for j in [-1,-2,-3]:\n",
    "        tmp=tmp[tmp[:,j]==False]\n",
    "    print(\"index \"+cali_path[-6]+\" valid number of data for calibration:\",tmp.shape[0])\n",
    "    cali_info=np.mean(tmp[:,:12],axis=0)\n",
    "    with open(cali_path,'wb') as f:\n",
    "        pickle.dump(cali_info,f)\n",
    "    return cali_info\n",
    "\n",
    "def convert_to_nparr(memory,color):\n",
    "    tmp=np.array(memory)\n",
    "    tmp_1=np.array(list(tmp[:,2]))\n",
    "    actions=np.array(list(tmp[:,3]))\n",
    "    tmp_2=tmp[:,-1]\n",
    "    tmp_2=tmp_2.astype(float)\n",
    "    states=np.concatenate((tmp_1,tmp_2.reshape(-1,1)),axis=1)\n",
    "    if color=='blue':\n",
    "        new_actions=np.copy(actions)\n",
    "        actions[:,0]=new_actions[:,1]\n",
    "        actions[:,1]=new_actions[:,0]\n",
    "    return states,actions\n",
    "\n",
    "def get_transformed_states(states,rmat,tvec,color):\n",
    "    transformed_states=np.zeros((states.shape[0],17))\n",
    "    corner_pos=np.zeros((states.shape[0],2))\n",
    "    transformed_states[:,1]=-rmat.T.dot((states[:,12:15]-tvec).T).T[:,0]\n",
    "    transformed_states[:,0]=rmat.T.dot((states[:,12:15]-tvec).T).T[:,1]\n",
    "    corner_pos[:,1]=-rmat.T.dot((states[:,15:18]-tvec).T).T[:,0]\n",
    "    corner_pos[:,0]=rmat.T.dot((states[:,15:18]-tvec).T).T[:,1]\n",
    "    transformed_states[:,2]=np.arctan2(corner_pos[:,1]-transformed_states[:,1],corner_pos[:,0]-transformed_states[:,0])\n",
    "    for i in range(4):\n",
    "        transformed_states[:,4+2*i]=-rmat.T.dot((states[:,18+3*i:21+3*i]-tvec).T).T[:,0]\n",
    "        transformed_states[:,3+2*i]=rmat.T.dot((states[:,18+3*i:21+3*i]-tvec).T).T[:,1]\n",
    "    for i in range(11,17):\n",
    "        transformed_states[:,i]=states[:,i+19]\n",
    "    ##########Need to be corrected later##############\n",
    "    if color== 'blue':\n",
    "        transformed_states[:,11:13]=transformed_states[:,11:13]\n",
    "    ##########Need to be corrected later##############\n",
    "    return transformed_states\n",
    "\n",
    "def process_train_states_and_actions(states,actions,with_finger,with_angle,with_med_filter,with_start_state):\n",
    "    checks=states[:,-4:]\n",
    "    \n",
    "    eps_ls=get_eps_ls(states,checks)\n",
    "    \n",
    "    states[:,:2] *= 1000.\n",
    "    if with_angle:\n",
    "        if with_finger:\n",
    "            states = states[:,[0,1,11,12,2,3,4,5,6,7,8,9,10]]\n",
    "            states[:,5:] *= 1000.\n",
    "        else:\n",
    "            states = states[:,[0,1,11,12,2]]        \n",
    "    else:\n",
    "        if with_finger:\n",
    "            states = states[:,[0,1,11,12,3,4,5,6,7,8,9,10]]\n",
    "            states[:,4:] *= 1000.\n",
    "        else:\n",
    "            states = states[:,[0, 1, 11, 12]]\n",
    "    if with_med_filter:\n",
    "        states=medfilter(eps_ls)\n",
    "    else:\n",
    "        states=states   \n",
    "        \n",
    "    if with_start_state:\n",
    "        new_eps_ls=get_eps_ls(states,checks)\n",
    "        checks_ls=np.split(checks,np.argwhere(checks[:,-1]==1).reshape(-1)+1,axis=0)\n",
    "        checks_ls.pop(-1)\n",
    "        all_grasp_states=np.zeros((actions.shape[0],states.shape[1]))\n",
    "        index=0\n",
    "        for i in range(len(new_eps_ls)):\n",
    "            eps=new_eps_ls[i]\n",
    "            grasp_states=np.tile(eps[0,:], (eps.shape[0], 1))\n",
    "            all_grasp_states[index:index+eps.shape[0],:]=grasp_states\n",
    "            if checks_ls[i][0,:].any():\n",
    "                checks[index:index+eps.shape[0],:]=np.ones((eps.shape[0],checks.shape[1]))\n",
    "                checks[index:index+eps.shape[0]-1,-1]=np.zeros(eps.shape[0]-1)\n",
    "            index=index+eps.shape[0]\n",
    "        actions=np.concatenate((actions,all_grasp_states),axis=1)\n",
    "    else:\n",
    "        actions=actions\n",
    "    \n",
    "    return states,actions,checks\n",
    "\n",
    "def get_eps_ls(states,checks):\n",
    "    ls=np.split(states,np.argwhere(checks[:,-1]==1).reshape(-1)+1,axis=0)\n",
    "    ls.pop(-1)\n",
    "    return ls\n",
    "\n",
    "def medfilter(eps_ls,W1=[40,40,100,100,None,40,40,40,40,40,40,40,40],W2=[40,40,100,100,40,40,40,40,40,40,40,40]):\n",
    "    new_states=np.empty((0,states.shape[1]))\n",
    "    state_dim=eps_ls[0].shape[1]\n",
    "    if state_dim==5 or state_dim==13:\n",
    "        W=W1\n",
    "        for eps in eps_ls:\n",
    "            for j in range(state_dim) :\n",
    "                x=eps[:,j]\n",
    "                x_new=np.copy(x)\n",
    "                if j!=4:\n",
    "                    w = int(W[j]/2)\n",
    "                    for i in range(0, x.shape[0]):\n",
    "                        if i < w:\n",
    "                            x_new[i] = np.mean(x[:i+w])\n",
    "                        elif i > x.shape[0]-w:\n",
    "                            x_new[i] = np.mean(x[i-w:])\n",
    "                        else:\n",
    "                            x_new[i] = np.mean(x[i-w:i+w])\n",
    "                    eps[:,j]=x_new\n",
    "            new_states=np.concatenate((new_states,eps),0)\n",
    "    else:\n",
    "        W=W2\n",
    "        for eps in eps_ls:\n",
    "            for j in range(state_dim) :\n",
    "                x=eps[:,j]\n",
    "                x_new=np.copy(x)\n",
    "                w = int(W[j]/2)\n",
    "                for i in range(0, x.shape[0]):\n",
    "                    if i < w:\n",
    "                        x_new[i] = np.mean(x[:i+w])\n",
    "                    elif i > x.shape[0]-w:\n",
    "                        x_new[i] = np.mean(x[i-w:])\n",
    "                    else:\n",
    "                        x_new[i] = np.mean(x[i-w:i+w])\n",
    "                eps[:,j]=x_new\n",
    "            new_states=np.concatenate((new_states,eps),0)\n",
    "    return new_states\n",
    "\n",
    "def get_final_dataset(states,actions,checks,valid_idx,real_len=None):\n",
    "    next_states=np.roll(states,-1,axis=0)\n",
    "    preprocess_sa=np.concatenate((states,actions),axis=1)\n",
    "    preprocess_sas=np.concatenate((preprocess_sa,next_states),axis=1)\n",
    "    #valid_idx=check_valid(checks)\n",
    "    #valid_idx=f_check_valid(states,checks)\n",
    "    final_sas=preprocess_sas[valid_idx]\n",
    "    preprocess_sasc=np.concatenate((preprocess_sas,valid_idx.reshape(-1,1)),axis=1)\n",
    "    if real_len==None:\n",
    "        return final_sas,states.shape[1],actions.shape[1]\n",
    "    else:\n",
    "        #return final_sas,states.shape[1],actions.shape[1],preprocess_sas[:real_len,:]\n",
    "        return final_sas,states.shape[1],actions.shape[1],preprocess_sasc[:real_len,:]\n",
    "    \n",
    "def check_valid(checks):\n",
    "    valid_idx_ls=((checks[:,-1]==0).astype(int)+(checks[:,-2]==0).astype(int)+(checks[:,-3]==0).astype(int)+(checks[:,-4]==0).astype(int))==4\n",
    "    prev_checks=np.roll(checks,-1,axis=0)\n",
    "    valid_prev_idx_ls=((prev_checks[:,-1]==0).astype(int)+(prev_checks[:,-2]==0).astype(int)+(prev_checks[:,-3]==0).astype(int)+(prev_checks[:,-4]==0).astype(int))==4\n",
    "    final_valid_idx_ls=((valid_idx_ls==1).astype(int)+(valid_prev_idx_ls==1).astype(int))==2\n",
    "    return final_valid_idx_ls\n",
    "\n",
    "def process_test_states_and_actions(states,actions,with_finger,with_angle,with_med_filter,with_start_state):\n",
    "    checks=states[:,-4:]\n",
    "    \n",
    "    eps_ls=get_eps_ls(states,checks)\n",
    "    \n",
    "    states[:,:2] *= 1000.\n",
    "    if with_angle:\n",
    "        if with_finger:\n",
    "            states = states[:,[0,1,11,12,2,3,4,5,6,7,8,9,10]]\n",
    "            states[:,5:] *= 1000.\n",
    "        else:\n",
    "            states = states[:,[0,1,11,12,2]]        \n",
    "    else:\n",
    "        if with_finger:\n",
    "            states = states[:,[0,1,11,12,3,4,5,6,7,8,9,10]]\n",
    "            states[:,4:] *= 1000.\n",
    "        else:\n",
    "            states = states[:,[0, 1, 11, 12]]\n",
    "    if with_med_filter:\n",
    "        #update checks based on b) and d)\n",
    "        states=medfilter(eps_ls)\n",
    "        #update checks in smooth (if len(valid_data)<=40, then checks first 3 columns =1)\n",
    "    else:\n",
    "        states=states   \n",
    "        \n",
    "    if with_start_state:\n",
    "        new_eps_ls=get_eps_ls(states,checks)\n",
    "        checks_ls=np.split(checks,np.argwhere(checks[:,-1]==1).reshape(-1)+1,axis=0)\n",
    "        checks_ls.pop(-1)\n",
    "        all_grasp_states=np.zeros((actions.shape[0],states.shape[1]))\n",
    "        index=0\n",
    "        for i in range(len(new_eps_ls)):\n",
    "            eps=new_eps_ls[i]\n",
    "            grasp_states=np.tile(eps[0,:], (eps.shape[0], 1))\n",
    "            all_grasp_states[index:index+eps.shape[0],:]=grasp_states\n",
    "            if checks_ls[i][0,:].any():\n",
    "                checks[index:index+eps.shape[0],:]=np.ones((eps.shape[0],checks.shape[1]))\n",
    "                checks[index:index+eps.shape[0]-1,-1]=np.zeros(eps.shape[0]-1)\n",
    "            index=index+eps.shape[0]\n",
    "        actions=np.concatenate((actions,all_grasp_states),axis=1)\n",
    "    else:\n",
    "        actions=actions\n",
    "    checks_ls=np.split(checks,np.argwhere(checks[:,-1]==1).reshape(-1)+1,axis=0)\n",
    "    checks_ls.pop(-1)\n",
    "    actions_ls=np.split(actions,np.argwhere(checks[:,-1]==1).reshape(-1)+1,axis=0)\n",
    "    actions_ls.pop(-1)\n",
    "    return new_eps_ls,actions_ls,checks_ls\n",
    "\n",
    "def get_test_ground_truth(test_ds,test_state_dim,test_action_dim):\n",
    "    test_states,test_actions,test_next_states=np.split(test_ds,[test_state_dim,test_state_dim+test_action_dim],axis=1)\n",
    "    test_traj=[test_states[0,:]]\n",
    "    for i in range(test_states.shape[0]-1):\n",
    "        if (test_next_states[i,:]==test_states[i+1,:]).all():\n",
    "            test_traj.append(test_next_states[i,:])\n",
    "        else:\n",
    "            test_traj.append(test_next_states[i,:])\n",
    "            test_traj.append(test_states[i+1,:])\n",
    "    test_traj.append(test_next_states[-1,:])\n",
    "    return test_traj\n",
    "\n",
    "def f_check_valid(states,checks):\n",
    "    ss=np.concatenate((states,np.roll(states,-1,axis=0)),axis=1)\n",
    "    prev=ss[:,:2]\n",
    "    prev_all=ss[:,:4]\n",
    "    nxt=ss[:,states.shape[1]:states.shape[1]+2]\n",
    "    nxt_all=ss[:,states.shape[1]:states.shape[1]+4]\n",
    "    conti=np.linalg.norm(prev-nxt,axis=1)<=1.2\n",
    "    non_equal=np.sum(prev_all-nxt_all==0,1)\n",
    "    ###看下smooth后 outlier是否还有，有的话数量多少！\n",
    "    final_valid_idx_ls=((non_equal!=4).astype(int)+(conti==1).astype(int)+(check_valid(checks)==1).astype(int))==3\n",
    "    ###看下smooth后 equal是否还有，有的话数量多少！最终最正确的不应该加conti\n",
    "    #final_valid_idx_ls=((conti==1).astype(int)+(check_valid(checks)==1).astype(int))==2\n",
    "    return final_valid_idx_ls\n",
    "\n",
    "def check_nonvalid_end(indices_arr,train_states,interval):\n",
    "    to_check=train_states[indices_arr[-interval-1:],:2]\n",
    "    diff=np.roll(to_check,-1,axis=0)-to_check\n",
    "    diff=diff[:interval,:]\n",
    "    valid=np.linalg.norm(diff,axis=1)<=1.2\n",
    "    if valid.all():\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not 2:\n",
    "    print(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py',\n",
       " '-f',\n",
       " '/Users/zsbjltwjj/Library/Jupyter/runtime/kernel-d4022927-3c8e-4044-bef7-faefaad1634e.json']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import argv\n",
    "argv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 valid number of data for calibration: 142065\n",
      "total valid number of episodes for training: 233\n",
      "96707\n"
     ]
    }
   ],
   "source": [
    "with_finger,with_angle,with_start_state,with_med_filter=False,False,True,False\n",
    "if 'wf' in data_mode:\n",
    "    with_finger=True\n",
    "if 'wa' in data_mode:\n",
    "    with_angle=True\n",
    "if 'ns' in data_mode:\n",
    "    with_start_state=False\n",
    "if 'wm' in data_mode:\n",
    "    with_med_filter=True\n",
    "obj_dir=base_path+color+'_data/'+obj\n",
    "if not os.path.exists(base_path+color+'_data/'+obj):\n",
    "    os.makedirs(obj_dir)\n",
    "cali_dir=obj_dir+'/cali'\n",
    "if not os.path.exists(cali_dir):\n",
    "    os.makedirs(cali_dir)\n",
    "test_dir=obj_dir+'/test'\n",
    "if not os.path.exists(test_dir):\n",
    "    os.makedirs(test_dir)\n",
    "\n",
    "train_paths=[]\n",
    "for idx in train_idx:\n",
    "    train_paths.append(base_path+color+'_data/'+'zs_raw_train_'+obj+'_'+color+'_'+data_type+'_v'+idx+'.obj')\n",
    "train_states=np.empty((0,17))\n",
    "train_actions=np.empty((0,2))\n",
    "for i in range(len(train_paths)):\n",
    "    idx=train_paths[i][-5]\n",
    "    with open(train_paths[i],'rb') as filehandler:\n",
    "        #memory: (base_rmat,base_tvec,obj_pos,corner_pos,finger_poses,no_detect,no_paral,drop),done\n",
    "        memory=pickle.load(filehandler,encoding='latin1')\n",
    "    same_idx_test_path=base_path+color+'_data/'+'zs_raw_test_'+obj+'_'+color+'_'+data_type+'_v'+idx+'.obj'\n",
    "    if os.path.exists(same_idx_test_path):\n",
    "        with open(same_idx_test_path,'rb') as filehandler:\n",
    "            test_memory=pickle.load(filehandler,encoding='latin1')\n",
    "        memory_for_cali=memory+test_memory\n",
    "    else:\n",
    "        memory_for_cali=memory\n",
    "    \n",
    "    cali_path=cali_dir+'/'+suffix+idx+'.cali'\n",
    "    if do_cali:\n",
    "        cali_info=cali(memory_for_cali,cali_path)\n",
    "    else:\n",
    "        with open(cali_path,'rb') as f:\n",
    "            cali_info=np.array(pickle.load(f))\n",
    "    rmat=cali_info[:9].reshape(3,3)\n",
    "    tvec=cali_info[9:]\n",
    "    states,actions=convert_to_nparr(memory,color)\n",
    "    transformed_states=get_transformed_states(states,rmat,tvec,color)\n",
    "    train_states=np.concatenate((train_states,transformed_states),axis=0)\n",
    "    train_actions=np.concatenate((train_actions,actions),axis=0)\n",
    "    \n",
    "if not train_separate:\n",
    "    train_states,train_actions,train_checks=process_train_states_and_actions(train_states,train_actions,with_finger,with_angle,with_med_filter,with_start_state)\n",
    "    train_ds,train_state_dim,train_action_dim=get_final_dataset(train_states,train_actions,train_checks)\n",
    "\n",
    "    print('total valid number of data for training:',train_ds.shape[0])\n",
    "    train_ds_path=obj_dir+'/train_full_'+data_type+'_v'+train_idx+data_mode\n",
    "    with open(train_ds_path,'wb') as f:\n",
    "        pickle.dump([train_ds,train_state_dim,train_action_dim],f)\n",
    "else:\n",
    "    train_states_ls,train_actions_ls,train_checks_ls=process_test_states_and_actions(train_states,train_actions,with_finger,with_angle,with_med_filter,with_start_state)\n",
    "    train_ds_ls,train_ds_all_ls, train_traj_gt_ls,real_train_actions_ls=[],[],[],[]\n",
    "    sm=0\n",
    "    for j in range(len(train_states_ls)):\n",
    "        train_states,train_actions,train_checks=train_states_ls[j],train_actions_ls[j],train_checks_ls[j]\n",
    "        \n",
    "        #train_final_valid_idx_ls=list(check_valid(train_checks))\n",
    "        train_final_valid_idx_ls=list(f_check_valid(train_states,train_checks))\n",
    "        if len(train_final_valid_idx_ls)!=0:\n",
    "            while train_final_valid_idx_ls[-1]==False:\n",
    "                train_final_valid_idx_ls.pop(-1)\n",
    "                if len(train_final_valid_idx_ls)==0:\n",
    "                    break\n",
    "        if len(train_final_valid_idx_ls)==0:\n",
    "            continue\n",
    "        real_len=len(train_final_valid_idx_ls)\n",
    "        #Deal with End\n",
    "        indices_arr=np.where(f_check_valid(train_states,train_checks)==True)[0]\n",
    "        if interval>0:\n",
    "            if check_nonvalid_end(indices_arr,train_states,interval):\n",
    "                real_len=indices_arr[-interval-1]+1\n",
    "        #Deal with End\n",
    "        train_valid_idx=f_check_valid(train_states,train_checks)\n",
    "        train_valid_idx[real_len:]=np.zeros(train_states.shape[0]-real_len,dtype=bool)\n",
    "        real_train_actions=train_actions[:real_len,:]\n",
    "        train_ds,train_state_dim,train_action_dim,train_ds_all=get_final_dataset(train_states,train_actions,train_checks,train_valid_idx,real_len)\n",
    "        train_traj_gt=get_test_ground_truth(train_ds,train_state_dim,train_action_dim)\n",
    "        \n",
    "        #print(str(j)+':'+str(train_ds.shape[0]))\n",
    "        #Deal with too short episode\n",
    "        if train_ds.shape[0]>100:\n",
    "            sm+=train_ds.shape[0]\n",
    "            train_ds_ls.append(train_ds)\n",
    "            train_ds_all_ls.append(train_ds_all)\n",
    "            train_traj_gt_ls.append(train_traj_gt)\n",
    "            real_train_actions_ls.append(real_train_actions)      \n",
    "    #train_ds_path=obj_dir+'/train_separate_'+data_type+'_v'+train_idx+data_mode\n",
    "    train_ds_path=obj_dir+'/train_separate_'+data_type+'_v'+train_idx+data_mode+'_'+suffix+'f'\n",
    "    print(\"total valid number of episodes for training:\",len(train_ds_ls))\n",
    "    print(sm)\n",
    "    with open(train_ds_path,'wb') as f:\n",
    "        pickle.dump([train_ds_ls,train_ds_all_ls,train_state_dim,train_action_dim,train_traj_gt_ls,real_train_actions_ls],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 the 0th episode: real length for prediction is 542, valid trajectory ground truth length is 353, valid data number is 352\n",
      "index 0 the 1th episode: real length for prediction is 643, valid trajectory ground truth length is 421, valid data number is 418\n",
      "total valid number of episodes for testing: 2\n"
     ]
    }
   ],
   "source": [
    "test_paths=[]\n",
    "for idx in test_idx:\n",
    "    test_paths.append(base_path+color+'_data/'+'zs_raw_test_'+obj+'_'+color+'_'+data_type+'_v'+idx+'.obj')\n",
    "test_states=np.empty((0,17))\n",
    "test_actions=np.empty((0,2))\n",
    "test_ds_ls,test_ds_all_ls,test_traj_gt_ls,real_test_actions_ls=[],[],[],[]\n",
    "for i in range(len(test_paths)):\n",
    "    idx=test_paths[i][-5]\n",
    "    with open(test_paths[i],'rb') as filehandler:\n",
    "        test_memory=pickle.load(filehandler,encoding='latin1')\n",
    "    cali_path=cali_dir+'/'+suffix+idx+'.cali'\n",
    "    with open(cali_path,'rb') as f:\n",
    "        cali_info=np.array(pickle.load(f))\n",
    "    rmat=cali_info[:9].reshape(3,3)\n",
    "    tvec=cali_info[9:]\n",
    "    states,test_actions=convert_to_nparr(test_memory,color)\n",
    "    test_transformed_states=get_transformed_states(states,rmat,tvec,color)\n",
    "    \n",
    "    test_states_ls,test_actions_ls,test_checks_ls=process_test_states_and_actions(test_transformed_states,test_actions,with_finger,with_angle,with_med_filter,with_start_state)\n",
    "    num=0\n",
    "    for j in range(len(test_states_ls)):\n",
    "        test_states,test_actions,test_checks=test_states_ls[j],test_actions_ls[j],test_checks_ls[j]\n",
    "        #test_final_valid_idx_ls=list(check_valid(test_checks))\n",
    "        test_final_valid_idx_ls=list(f_check_valid(test_states,test_checks))\n",
    "        if len(test_final_valid_idx_ls)!=0:\n",
    "            while test_final_valid_idx_ls[-1]==False:\n",
    "                test_final_valid_idx_ls.pop(-1)\n",
    "                if len(test_final_valid_idx_ls)==0:\n",
    "                    break\n",
    "        if len(test_final_valid_idx_ls)==0:\n",
    "            continue\n",
    "        real_len=len(test_final_valid_idx_ls)\n",
    "        #Deal with End\n",
    "        indices_arr=np.where(f_check_valid(test_states,test_checks)==True)[0]\n",
    "        if interval>0:\n",
    "            if check_nonvalid_end(indices_arr,test_states,interval):\n",
    "                real_len=indices_arr[-interval-1]+1\n",
    "        #Deal with End\n",
    "        test_valid_idx=f_check_valid(test_states,test_checks)\n",
    "        test_valid_idx[real_len:]=np.zeros(test_states.shape[0]-real_len,dtype=bool)\n",
    "        real_test_actions=test_actions[:real_len,:]\n",
    "        test_ds,test_state_dim,test_action_dim,test_ds_all=get_final_dataset(test_states,test_actions,test_checks,test_valid_idx,real_len)\n",
    "        test_traj_gt=get_test_ground_truth(test_ds,test_state_dim,test_action_dim)\n",
    "        #print(str(j)+':'+str(test_ds.shape[0]))\n",
    "        #Deal with too short episode\n",
    "        if test_ds.shape[0]>100:\n",
    "            print(\"index %s the %sth episode: real length for prediction is %s, valid trajectory ground truth length is %s, valid data number is %s\" % (i, j,real_len,len(test_traj_gt),test_ds.shape[0]))\n",
    "            test_ds_ls.append(test_ds)\n",
    "            test_ds_all_ls.append(test_ds_all)\n",
    "            test_traj_gt_ls.append(test_traj_gt)\n",
    "            real_test_actions_ls.append(real_test_actions)\n",
    "            #test_ds_path=test_dir+'/test_'+data_type+'_v'+idx+data_mode+'_'+str(j)\n",
    "            test_ds_path=test_dir+'/test_'+data_type+'_v'+idx+data_mode+'_'+str(num)+'_'+suffix+'f'\n",
    "            with open(test_ds_path,'wb') as f:\n",
    "                pickle.dump([test_ds,test_ds_all,test_state_dim,test_action_dim,test_traj_gt,real_test_actions],f)\n",
    "            num+=1\n",
    "\n",
    "#test_ds_path=test_dir+'/test_separate_'+data_type+'_v'+test_idx+data_mode\n",
    "test_ds_path=test_dir+'/test_separate_'+data_type+'_v'+test_idx+data_mode+'_'+suffix+'f'\n",
    "print(\"total valid number of episodes for testing:\",len(test_ds_ls))\n",
    "with open(test_ds_path,'wb') as f:\n",
    "    pickle.dump([test_ds_ls,test_ds_all_ls,test_state_dim,test_action_dim,test_traj_gt_ls,real_test_actions_ls],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test(ls,mix_idx_ls):\n",
    "    return [i for j, i in enumerate(ls) if j not in mix_idx_ls],[ls[i] for i in mix_idx_ls]\n",
    "if mix:\n",
    "    all_ds_ls=train_ds_ls+test_ds_ls\n",
    "    all_ds_all_ls=train_ds_all_ls+test_ds_all_ls\n",
    "    all_traj_gt_ls=train_traj_gt_ls+test_traj_gt_ls\n",
    "    real_all_actions_ls=real_train_actions_ls+real_test_actions_ls\n",
    "    train_ds_ls,test_ds_ls=make_train_test(all_ds_ls,mix_idx_ls)\n",
    "    train_ds_all_ls,test_ds_all_ls=make_train_test(all_ds_all_ls,mix_idx_ls)\n",
    "    train_traj_gt_ls,test_traj_gt_ls=make_train_test(all_traj_gt_ls,mix_idx_ls)\n",
    "    real_train_actions_ls,real_test_actions_ls=make_train_test(real_all_actions_ls,mix_idx_ls)\n",
    "    \n",
    "    train_ds_path=obj_dir+'/train_separate_'+data_type+'_v'+train_idx+data_mode+'_'+suffix+'f'\n",
    "    print(\"total valid number of episodes for training:\",len(train_ds_ls))\n",
    "    with open(train_ds_path,'wb') as f:\n",
    "        pickle.dump([train_ds_ls,train_ds_all_ls,train_state_dim,train_action_dim,train_traj_gt_ls,real_train_actions_ls],f)\n",
    "    test_ds_path=test_dir+'/test_separate_'+data_type+'_v'+test_idx+data_mode+'_'+suffix+'f'\n",
    "    print(\"total valid number of episodes for testing:\",len(test_ds_ls))\n",
    "    with open(test_ds_path,'wb') as f:\n",
    "        pickle.dump([test_ds_ls,test_ds_all_ls,test_state_dim,test_action_dim,test_traj_gt_ls,real_test_actions_ls],f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
